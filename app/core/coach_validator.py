"""
Coach ì‘ë‹µ ê²€ì¦ ëª¨ë“ˆ.

COACH_PROMPT_V2ì˜ JSON ì¶œë ¥ì„ Pydantic ëª¨ë¸ë¡œ ê²€ì¦í•˜ê³  íŒŒì‹±í•©ë‹ˆë‹¤.
LLM ì¶œë ¥ì˜ ì¼ê´€ì„±ì„ ë³´ì¥í•˜ê³ , ì˜ëª»ëœ í˜•ì‹ì˜ ì‘ë‹µì„ ê°ì§€í•©ë‹ˆë‹¤.
"""

import json
import logging
import re
from typing import List, Literal, Optional, Union
from pydantic import BaseModel, Field, field_validator, BeforeValidator
from typing_extensions import Annotated

logger = logging.getLogger(__name__)


# ============================================================
# Pydantic Models for Coach Response
# ============================================================


class KeyMetric(BaseModel):
    """í•µì‹¬ ì§€í‘œ ëª¨ë¸"""

    label: str = Field(..., max_length=30, description="ì§€í‘œëª…")
    # ë¬¸ìì—´ë¡œ ìë™ ë³€í™˜ (LLMì´ ìˆ«ìë¡œ ì£¼ëŠ” ê²½ìš° ëŒ€ë¹„)
    value: Annotated[Union[str, int, float], BeforeValidator(str)] = Field(
        ..., max_length=50, description="ìˆ˜ì¹˜"
    )
    status: Literal["good", "warning", "danger"] = Field(
        default="warning", description="í‰ê°€ (good/warning/danger)"
    )
    trend: Literal["up", "down", "neutral"] = Field(default="neutral")
    is_critical: bool = Field(default=False)

    @field_validator("status", mode="before")
    @classmethod
    def normalize_status(cls, v: str) -> str:
        """ìƒíƒœ ê°’ì„ ì˜ì–´ë¡œ ì •ê·œí™” (í•œê¸€â†’ì˜ì–´ í†µì¼)"""
        if not isinstance(v, str):
            return "warning"
        normalized = v.lower().strip()
        if normalized in ["ì–‘í˜¸", "good", "positive", "ìµœìƒ"]:
            return "good"
        elif normalized in ["ì£¼ì˜", "warning", "caution", "ë³´í†µ"]:
            return "warning"
        elif normalized in ["ìœ„í—˜", "danger", "critical", "bad"]:
            return "danger"
        return "warning"  # ì•Œ ìˆ˜ ì—†ëŠ” ê°’ì€ warningìœ¼ë¡œ ê¸°ë³¸ ì²˜ë¦¬


class RiskItem(BaseModel):
    """ìœ„í—˜ ìš”ì†Œ ëª¨ë¸"""

    area: str = Field(..., description="ì˜ì—­ (bullpen/starter/batting/defense)")
    level: Literal[0, 1, 2] = Field(..., description="ìœ„í—˜ë„ (0=ìœ„í—˜, 1=ì£¼ì˜, 2=ì–‘í˜¸)")
    description: str = Field(..., max_length=150, description="ìœ„í—˜ ì„¤ëª… (ìµœëŒ€ 150ì)")

    @field_validator("area", mode="before")
    @classmethod
    def normalize_area(cls, v: str) -> str:
        """ì˜ì—­ ê°’ì„ ì˜ì–´ë¡œ ì •ê·œí™”"""
        if not isinstance(v, str):
            return "overall"
        normalized = v.lower().strip()
        area_mapping = {
            "ë¶ˆíœ": "bullpen",
            "bullpen": "bullpen",
            "ë¦´ë¦¬í”„": "bullpen",
            "ì„ ë°œ": "starter",
            "starter": "starter",
            "starting": "starter",
            "íƒ€ê²©": "batting",
            "batting": "batting",
            "íƒ€ì„ ": "batting",
            "ìˆ˜ë¹„": "defense",
            "defense": "defense",
            "ì „ì²´": "overall",
            "overall": "overall",
        }
        return area_mapping.get(normalized, "overall")


class AnalysisSection(BaseModel):
    """ë¶„ì„ ì„¹ì…˜ ëª¨ë¸"""

    strengths: List[str] = Field(default_factory=list, description="ê°•ì  ëª©ë¡")
    weaknesses: List[str] = Field(default_factory=list, description="ì•½ì  ëª©ë¡")
    risks: List[RiskItem] = Field(default_factory=list, description="ìœ„í—˜ ìš”ì†Œ ëª©ë¡")


class CoachResponse(BaseModel):
    """
    Coach ì‘ë‹µ ì „ì²´ ëª¨ë¸.

    COACH_PROMPT_V2ì˜ JSON ìŠ¤í‚¤ë§ˆì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
    """

    headline: str = Field(
        ..., min_length=5, max_length=60, description="í•œ ì¤„ ì§„ë‹¨ (ìµœëŒ€ 60ì)"
    )
    sentiment: Literal["positive", "negative", "neutral"] = Field(default="neutral")
    key_metrics: List[KeyMetric] = Field(
        default_factory=list, description="í•µì‹¬ ì§€í‘œ ëª©ë¡ (ìµœëŒ€ 6ê°œ)"
    )
    analysis: AnalysisSection = Field(default_factory=AnalysisSection)
    detailed_markdown: str = Field(
        default="", max_length=500, description="ìƒì„¸ ë¶„ì„ ë§ˆí¬ë‹¤ìš´ (ìµœëŒ€ 500ì)"
    )
    coach_note: str = Field(
        default="", max_length=120, description="ì „ëµì  ì œì–¸ (ìµœëŒ€ 120ì)"
    )

    @field_validator("headline", mode="before")
    @classmethod
    def truncate_headline(cls, v: str) -> str:
        """headline ê¸¸ì´ ì œí•œ ë° ì •ë¦¬"""
        if not isinstance(v, str) or not v.strip():
            raise ValueError("headlineì€ ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        v = v.strip()

        # [Fix] "headline": "Title" í˜•íƒœì˜ ì¤‘ë³µ í‚¤ íŒ¨í„´ ì œê±°
        # LLMì´ JSON í˜•ì‹ì„ ê°’ ì•ˆì— í¬í•¨ì‹œí‚¤ëŠ” í™˜ê° ë°©ì§€
        import re

        dup_pattern = r'^"headline"\s*:\s*"(.*)"$'
        match = re.match(dup_pattern, v)
        if match:
            v = match.group(1)

        # [Fix] ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§„ ê²½ìš° ì œê±°
        if v.startswith('"') and v.endswith('"'):
            v = v[1:-1]

        if len(v) > 60:
            v = v[:57] + "..."
        return v

    @field_validator("detailed_markdown", mode="before")
    @classmethod
    def truncate_markdown(cls, v: str) -> str:
        """detailed_markdown ê¸¸ì´ ì œí•œ (í”„ë¡¬í”„íŠ¸ ê·œì¹™: ìµœëŒ€ 500ì)"""
        if not isinstance(v, str):
            return ""
        v = v.strip()
        if len(v) > 500:
            v = v[:497] + "..."
        return v

    @field_validator("coach_note", mode="before")
    @classmethod
    def truncate_coach_note(cls, v: str) -> str:
        """coach_note ê¸¸ì´ ì œí•œ (í”„ë¡¬í”„íŠ¸ ê·œì¹™: ìµœëŒ€ 120ì)"""
        if not isinstance(v, str):
            return ""
        v = v.strip()
        if len(v) > 120:
            v = v[:117] + "..."
        return v

    @field_validator("key_metrics", mode="before")
    @classmethod
    def limit_metrics(cls, v: list) -> list:
        """key_metrics ê°œìˆ˜ ì œí•œ (ìµœëŒ€ 6ê°œ)"""
        if not isinstance(v, list):
            return []
        return v[:6]


# ============================================================
# Parser Functions
# ============================================================


def extract_json_from_response(raw_response: str) -> Optional[str]:
    """
    LLM ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    ë‹¤ì–‘í•œ í˜•ì‹ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤:
    - ìˆœìˆ˜ JSON
    - ```json ... ``` ì½”ë“œ ë¸”ë¡
    - ì•ë’¤ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” JSON
    """
    if not raw_response:
        return None

    text = raw_response.strip()

    # Case 1: ```json ì½”ë“œ ë¸”ë¡
    json_block_pattern = r"```(?:json)?\s*([\s\S]*?)```"
    matches = re.findall(json_block_pattern, text)
    if matches:
        return matches[0].strip()

    # Case 2: { ... } JSON ê°ì²´ ì§ì ‘ ì°¾ê¸°
    # ê°€ì¥ ë°”ê¹¥ìª½ ì¤‘ê´„í˜¸ ë§¤ì¹­
    brace_count = 0
    start_idx = -1
    end_idx = -1

    for i, char in enumerate(text):
        if char == "{":
            if brace_count == 0:
                start_idx = i
            brace_count += 1
        elif char == "}":
            brace_count -= 1
            if brace_count == 0 and start_idx != -1:
                end_idx = i + 1
                break

    if start_idx != -1 and end_idx != -1:
        return text[start_idx:end_idx]

    return None


from typing import List, Literal, Optional, Union, Tuple


def parse_coach_response(
    raw_response: str,
) -> Tuple[Optional[CoachResponse], Optional[str]]:
    """
    LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ CoachResponse ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        raw_response: LLMì˜ ì›ì‹œ ì‘ë‹µ ë¬¸ìì—´

    Returns:
        CoachResponse ê°ì²´. íŒŒì‹± ì‹¤íŒ¨ ì‹œ None ë°˜í™˜ (ìºì‹œ FAILED ì²˜ë¦¬ìš©).
    """
    if not raw_response or not raw_response.strip():
        return None, "Empty response"

    try:
        # JSON ì¶”ì¶œ
        json_str = extract_json_from_response(raw_response)

        # [Fix] JSONì„ ëª» ì°¾ì•˜ì§€ë§Œ, í…ìŠ¤íŠ¸ê°€ "headline": ... í˜•íƒœë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° (Missing braces)
        # Solar Pro ëª¨ë¸ì´ ê°€ë” ì—¬ëŠ” ê´„í˜¸ë¥¼ ë¹¼ë¨¹ëŠ” ê²½ìš° ì²˜ë¦¬
        if not json_str and raw_response.strip().startswith('"headline"'):
            logger.warning(
                "[CoachValidator] Missing braces detected, attempting to wrap with {}"
            )
            # ë§¨ ë’¤ì— }ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ì¶”ê°€
            temp_json = "{" + raw_response.strip()
            if not temp_json.endswith("}"):
                temp_json += "}"

            # ë‹¤ì‹œ ì‹œë„
            try:
                data = json.loads(temp_json)
                return CoachResponse(**data), None
            except Exception as e:
                logger.warning(f"Fallback parsing failed: {e}")
                pass  # ì‹¤íŒ¨í•˜ë©´ ì›ë˜ ë¡œì§ëŒ€ë¡œ ì§„í–‰

        if not json_str:
            return None, "No JSON found"

        # JSON íŒŒì‹±
        try:
            data = json.loads(json_str)
        except json.JSONDecodeError as e:
            logger.warning(f"[CoachValidator] JSON decode error: {e}")
            return None, f"JSON decode error: {e}"

        # Pydantic ê²€ì¦
        try:
            return CoachResponse(**data), None
        except Exception as e:
            logger.warning(f"[CoachValidator] Pydantic validation error: {e}")
            return None, f"Validation error: {e}"

    except Exception as e:
        logger.error(f"[CoachValidator] Failed to parse coach response: {e}")
        return None, f"Unknown error: {e}"


def _create_fallback_response(error_reason: str, original_text: str) -> CoachResponse:
    """
    íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë³´ì¡´í•˜ëŠ” fallback ì‘ë‹µ ìƒì„±.

    ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ì‚¬ìš©ìì—ê²Œ ìµœì†Œí•œì˜ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì²« ì¤„ ì¶”ì¶œ ì‹œë„
    first_meaningful_line = ""
    if original_text:
        for line in original_text.strip().split("\n"):
            cleaned = line.strip()
            # [Fix] '{', '```', '#' ë¿ë§Œ ì•„ë‹ˆë¼ '"headline"' ê°™ì€ JSON fragmentë„ ë¬´ì‹œ
            if cleaned and not cleaned.startswith(("{", "```", "#", '"')):
                first_meaningful_line = cleaned[:100]  # ìµœëŒ€ 100ì
                break

    headline = first_meaningful_line or "AI ë¶„ì„ ê²°ê³¼"

    # ì›ë³¸ í…ìŠ¤íŠ¸ ì •ë¦¬ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡, JSON ì”í•´ ì œê±°)
    cleaned_text = original_text.strip() if original_text else ""
    for prefix in ["```json", "```", "{"]:
        if cleaned_text.startswith(prefix):
            cleaned_text = cleaned_text[len(prefix) :]
    for suffix in ["```", "}"]:
        if cleaned_text.endswith(suffix):
            cleaned_text = cleaned_text[: -len(suffix)]
    cleaned_text = cleaned_text.strip()

    return CoachResponse(
        headline=headline,
        sentiment="neutral",
        key_metrics=[],
        analysis=AnalysisSection(strengths=[], weaknesses=[], risks=[]),
        detailed_markdown="",
        coach_note=(
            cleaned_text[:2000] if cleaned_text else f"í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨: {error_reason}"
        ),
    )


def validate_coach_response(response: CoachResponse) -> List[str]:
    """
    CoachResponseì˜ ë°ì´í„° í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤.

    Returns:
        ê²½ê³  ë©”ì‹œì§€ ëª©ë¡ (ë¹„ì–´ìˆìœ¼ë©´ ì–‘í˜¸)
    """
    warnings = []

    # í•µì‹¬ ì§€í‘œ ê°œìˆ˜ í™•ì¸
    critical_count = sum(1 for m in response.key_metrics if m.is_critical)
    if critical_count > 2:
        warnings.append(
            f"í•µì‹¬ ì§€í‘œ(is_critical=true)ê°€ {critical_count}ê°œì…ë‹ˆë‹¤. ìµœëŒ€ 2ê°œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
        )

    # ë¶„ì„ ë‚´ìš© í™•ì¸
    if not response.analysis.strengths and not response.analysis.weaknesses:
        warnings.append("ê°•ì ê³¼ ì•½ì ì´ ëª¨ë‘ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    # coach_note ê¸¸ì´ í™•ì¸
    if len(response.coach_note) < 20:
        warnings.append("coach_noteê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì „ëµ ì œì–¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

    # ì„ ìˆ˜ëª… í¬í•¨ ì—¬ë¶€ í™•ì¸ (í’ˆì§ˆ ì§€í‘œ)
    all_text = " ".join(response.analysis.strengths + response.analysis.weaknesses)
    if all_text:
        # í•œê¸€ ì´ë¦„ íŒ¨í„´ (2-4ê¸€ì í•œê¸€ ì´ë¦„)
        korean_name_pattern = r"[ê°€-í£]{2,4}"
        if not re.search(korean_name_pattern, all_text):
            warnings.append("ë¶„ì„ì— ì„ ìˆ˜ëª…ì´ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. êµ¬ì²´ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")

        # ìˆ˜ì¹˜ ë°ì´í„° í¬í•¨ ì—¬ë¶€ í™•ì¸
        number_pattern = r"\d+\.?\d*"
        if not re.search(number_pattern, all_text):
            warnings.append("ë¶„ì„ì— ìˆ˜ì¹˜ ë°ì´í„°ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    return warnings


def format_coach_response_as_markdown(response: CoachResponse) -> str:
    """
    CoachResponseë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    JSON ì‘ë‹µì„ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë Œë”ë§í•˜ê¸° ì¢‹ì€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    parts = []

    # í—¤ë“œë¼ì¸
    sentiment_emoji = {"positive": "ğŸŸ¢", "negative": "ğŸ”´", "neutral": "ğŸŸ¡"}.get(
        response.sentiment, "âšª"
    )
    parts.append(f"## {sentiment_emoji} {response.headline}\n")

    # í•µì‹¬ ì§€í‘œ í…Œì´ë¸”
    if response.key_metrics:
        parts.append("### í•µì‹¬ ì§€í‘œ")
        parts.append("| ì§€í‘œ | ìˆ˜ì¹˜ | ìƒíƒœ | ì¶”ì„¸ |")
        parts.append("|------|------|------|------|")

        trend_symbol = {"up": "ğŸ“ˆ", "down": "ğŸ“‰", "neutral": "â¡ï¸"}
        for m in response.key_metrics:
            critical_mark = "**" if m.is_critical else ""
            trend = trend_symbol.get(m.trend, "")
            parts.append(
                f"| {critical_mark}{m.label}{critical_mark} | {m.value} | {m.status} | {trend} |"
            )
        parts.append("")

    # ë¶„ì„ ì„¹ì…˜
    if response.analysis.strengths:
        parts.append("### ğŸ’ª ê°•ì ")
        for s in response.analysis.strengths:
            parts.append(f"- {s}")
        parts.append("")

    if response.analysis.weaknesses:
        parts.append("### âš ï¸ ì•½ì ")
        for w in response.analysis.weaknesses:
            parts.append(f"- {w}")
        parts.append("")

    if response.analysis.risks:
        parts.append("### ğŸš¨ ìœ„í—˜ ìš”ì†Œ")
        risk_emoji = {0: "ğŸ”´", 1: "ğŸŸ¡", 2: "ğŸŸ¢"}
        for r in response.analysis.risks:
            emoji = risk_emoji.get(r.level, "âšª")
            parts.append(f"- {emoji} **{r.area}**: {r.description}")
        parts.append("")

    # ìƒì„¸ ë¶„ì„ (ì´ë¯¸ ë§ˆí¬ë‹¤ìš´)
    if response.detailed_markdown:
        parts.append(response.detailed_markdown)
        parts.append("")

    # Coach's Note
    if response.coach_note:
        parts.append("### ğŸ’¡ Coach's Note")
        parts.append(response.coach_note)
        parts.append("")

    return "\n".join(parts)
