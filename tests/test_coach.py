"""
Coach ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ.

Fast Path, ìºì‹±, ì‘ë‹µ ê²€ì¦ê¸° ë“±ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import pytest
import json
import asyncio
from unittest.mock import Mock, patch, AsyncMock, MagicMock
from datetime import datetime

# ============================================================
# Coach Validator Tests
# ============================================================


class TestCoachValidator:
    """Coach ì‘ë‹µ ê²€ì¦ê¸° í…ŒìŠ¤íŠ¸"""

    def test_extract_json_from_pure_json(self):
        """ìˆœìˆ˜ JSON ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        from app.core.coach_validator import extract_json_from_response

        raw = '{"headline": "í…ŒìŠ¤íŠ¸", "sentiment": "neutral"}'
        result = extract_json_from_response(raw)
        assert result is not None
        assert "headline" in result

    def test_extract_json_from_code_block(self):
        """ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        from app.core.coach_validator import extract_json_from_response

        raw = """ì—¬ê¸° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

```json
{"headline": "ì„ ë°œ ë¶•ê´´ê°€ ë¶ˆíœ ê³¼ë¶€í•˜ë¡œ ì§ê²°", "sentiment": "negative"}
```

ìœ„ ë¶„ì„ì„ ì°¸ê³ í•˜ì„¸ìš”."""

        result = extract_json_from_response(raw)
        assert result is not None
        data = json.loads(result)
        assert data["headline"] == "ì„ ë°œ ë¶•ê´´ê°€ ë¶ˆíœ ê³¼ë¶€í•˜ë¡œ ì§ê²°"
        assert data["sentiment"] == "negative"

    def test_extract_json_from_mixed_text(self):
        """í˜¼í•© í…ìŠ¤íŠ¸ì—ì„œ JSON ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        from app.core.coach_validator import extract_json_from_response

        raw = """ë¶„ì„ ì‹œì‘
{"headline": "í…ŒìŠ¤íŠ¸ í—¤ë“œë¼ì¸", "sentiment": "positive", "key_metrics": []}
ë¶„ì„ ì¢…ë£Œ"""

        result = extract_json_from_response(raw)
        assert result is not None
        data = json.loads(result)
        assert data["headline"] == "í…ŒìŠ¤íŠ¸ í—¤ë“œë¼ì¸"

    def test_parse_valid_coach_response(self):
        """ìœ íš¨í•œ Coach ì‘ë‹µ íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        from app.core.coach_validator import parse_coach_response

        raw = """{
            "headline": "KIA íƒ€ì´ê±°ì¦ˆ ì„ ë°œì§„ ì•ˆì •í™” í•„ìš”",
            "sentiment": "negative",
            "key_metrics": [
                {"label": "íŒ€ ERA", "value": "4.52", "status": "ì£¼ì˜", "trend": "up", "is_critical": true}
            ],
            "analysis": {
                "strengths": ["íƒ€ì„  ìƒì‚°ë ¥ ì–‘í˜¸"],
                "weaknesses": ["ë¶ˆíœ ê³¼ë¶€í•˜"],
                "risks": [{"area": "ë¶ˆíœ", "level": 0, "description": "ë¦¬ê·¸ í‰ê·  ëŒ€ë¹„ 7%p ë†’ì€ ë¶ˆíœ ë¹„ì¤‘"}]
            },
            "detailed_markdown": "## ìƒì„¸ ë¶„ì„\\ní…ŒìŠ¤íŠ¸ ë‚´ìš©",
            "coach_note": "ì„ ë°œ ë¡œí…Œì´ì…˜ ì¬ì •ë¹„ê°€ ì‹œê¸‰í•©ë‹ˆë‹¤."
        }"""

        response = parse_coach_response(raw)
        assert response is not None
        assert response.headline == "KIA íƒ€ì´ê±°ì¦ˆ ì„ ë°œì§„ ì•ˆì •í™” í•„ìš”"
        assert response.sentiment == "negative"
        assert len(response.key_metrics) == 1
        assert response.key_metrics[0].is_critical is True
        assert len(response.analysis.risks) == 1
        assert response.analysis.risks[0].level == 0

    def test_parse_invalid_json(self):
        """ì˜ëª»ëœ JSON íŒŒì‹± ì‹œ None ë°˜í™˜ í…ŒìŠ¤íŠ¸"""
        from app.core.coach_validator import parse_coach_response

        raw = "ì´ê²ƒì€ JSONì´ ì•„ë‹™ë‹ˆë‹¤."
        response = parse_coach_response(raw)
        assert response is None

    def test_validate_coach_response_warnings(self):
        """Coach ì‘ë‹µ ê²€ì¦ ê²½ê³  í…ŒìŠ¤íŠ¸"""
        from app.core.coach_validator import (
            CoachResponse,
            validate_coach_response,
            KeyMetric,
            AnalysisSection,
        )

        # í•µì‹¬ ì§€í‘œê°€ 4ê°œ ì´ìƒì¸ ê²½ìš° ê²½ê³ 
        response = CoachResponse(
            headline="í…ŒìŠ¤íŠ¸ í—¤ë“œë¼ì¸",
            sentiment="neutral",
            key_metrics=[
                KeyMetric(label=f"ì§€í‘œ{i}", value="1", status="ì–‘í˜¸", is_critical=True)
                for i in range(4)
            ],
            analysis=AnalysisSection(),
            coach_note="ì§§ìŒ",  # 20ì ë¯¸ë§Œ
        )

        warnings = validate_coach_response(response)
        assert len(warnings) >= 2  # í•µì‹¬ ì§€í‘œ ì´ˆê³¼ + coach_note ì§§ìŒ

    def test_format_coach_response_as_markdown(self):
        """Coach ì‘ë‹µ ë§ˆí¬ë‹¤ìš´ ë³€í™˜ í…ŒìŠ¤íŠ¸"""
        from app.core.coach_validator import (
            CoachResponse,
            format_coach_response_as_markdown,
            KeyMetric,
            AnalysisSection,
            RiskItem,
        )

        response = CoachResponse(
            headline="íŒ€ ìƒíƒœ ì–‘í˜¸",
            sentiment="positive",
            key_metrics=[
                KeyMetric(
                    label="OPS",
                    value=".850",
                    status="ì–‘í˜¸",
                    trend="up",
                    is_critical=True,
                )
            ],
            analysis=AnalysisSection(
                strengths=["ê°•ë ¥í•œ íƒ€ì„ "],
                weaknesses=["ë¶ˆíœ ë¶ˆì•ˆ"],
                risks=[RiskItem(area="ë¶ˆíœ", level=1, description="ì£¼ì˜ í•„ìš”")],
            ),
            detailed_markdown="## ìƒì„¸ ë¶„ì„\ní…ŒìŠ¤íŠ¸ ë‚´ìš©",
            coach_note="ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ê¶Œì¥í•©ë‹ˆë‹¤.",
        )

        markdown = format_coach_response_as_markdown(response)
        assert "ğŸŸ¢" in markdown  # positive sentiment
        assert "OPS" in markdown
        assert "ê°•ë ¥í•œ íƒ€ì„ " in markdown
        assert "Coach's Note" in markdown


# ============================================================
# TTL Cache Tests
# ============================================================


class TestTTLCache:
    """TTL ìºì‹œ í…ŒìŠ¤íŠ¸"""

    def test_cache_set_and_get(self):
        """ìºì‹œ ì„¤ì • ë° ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
        from app.tools.database_query import TTLCache

        cache = TTLCache(ttl_seconds=60)
        cache.set("test_key", {"data": "value"})

        result = cache.get("test_key")
        assert result is not None
        assert result["data"] == "value"

    def test_cache_miss(self):
        """ìºì‹œ ë¯¸ìŠ¤ í…ŒìŠ¤íŠ¸"""
        from app.tools.database_query import TTLCache

        cache = TTLCache(ttl_seconds=60)
        result = cache.get("nonexistent_key")
        assert result is None

    def test_cache_expiry(self):
        """ìºì‹œ ë§Œë£Œ í…ŒìŠ¤íŠ¸"""
        import time
        from app.tools.database_query import TTLCache

        cache = TTLCache(ttl_seconds=1)  # 1ì´ˆ TTL
        cache.set("expire_key", "value")

        # ì¦‰ì‹œ ì¡°íšŒ - ì¡´ì¬í•´ì•¼ í•¨
        assert cache.get("expire_key") == "value"

        # 1.5ì´ˆ ëŒ€ê¸° í›„ ì¡°íšŒ - ë§Œë£Œë¨
        time.sleep(1.5)
        assert cache.get("expire_key") is None

    def test_cache_max_size(self):
        """ìºì‹œ ìµœëŒ€ í¬ê¸° í…ŒìŠ¤íŠ¸"""
        from app.tools.database_query import TTLCache

        cache = TTLCache(ttl_seconds=60, max_size=3)

        # 4ê°œ í•­ëª© ì¶”ê°€ (ìµœëŒ€ í¬ê¸° ì´ˆê³¼)
        for i in range(4):
            cache.set(f"key_{i}", f"value_{i}")

        # ìµœëŒ€ 3ê°œë§Œ ìœ ì§€
        stats = cache.stats()
        assert stats["total_entries"] <= 3

    def test_cache_stats(self):
        """ìºì‹œ í†µê³„ í…ŒìŠ¤íŠ¸"""
        from app.tools.database_query import TTLCache

        cache = TTLCache(ttl_seconds=60, max_size=10)
        cache.set("key1", "value1")
        cache.set("key2", "value2")

        stats = cache.stats()
        assert stats["total_entries"] == 2
        assert stats["ttl_seconds"] == 60
        assert stats["max_size"] == 10


# ============================================================
# Tool Caller Parallel Execution Tests
# ============================================================


class TestToolCallerParallel:
    """ë³‘ë ¬ ë„êµ¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""

    @pytest.mark.asyncio
    async def test_execute_multiple_tools_parallel(self):
        """
        ë³‘ë ¬ ë„êµ¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸

        [P3 Fix] ì‹œê°„ ê¸°ë°˜ ê²€ì¦ ëŒ€ì‹  Mock ê¸°ë°˜ ë™ì‹œì„± ê²€ì¦ìœ¼ë¡œ ìˆ˜ì •.
        ë‘ ë„êµ¬ê°€ ê±°ì˜ ë™ì‹œì— ì‹œì‘ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì—¬ CI í™˜ê²½ì—ì„œë„ ì•ˆì •ì ìœ¼ë¡œ í†µê³¼.
        """
        import time
        import threading
        from app.agents.tool_caller import ToolCaller, ToolCall, ToolResult

        caller = ToolCaller()
        call_times = []
        call_lock = threading.Lock()

        # ì‹œì‘ ì‹œê°„ì„ ê¸°ë¡í•˜ëŠ” ì¶”ì  ë„êµ¬
        def tracking_tool_1(param1: str) -> dict:
            with call_lock:
                call_times.append(("tool_1", time.time()))
            time.sleep(0.1)  # ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            return {"result": f"tool1: {param1}"}

        def tracking_tool_2(param2: str) -> dict:
            with call_lock:
                call_times.append(("tool_2", time.time()))
            time.sleep(0.1)  # ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            return {"result": f"tool2: {param2}"}

        caller.register_tool(
            "tracking_tool_1",
            "Tracking tool 1",
            {"param1": "Parameter 1"},
            tracking_tool_1,
        )
        caller.register_tool(
            "tracking_tool_2",
            "Tracking tool 2",
            {"param2": "Parameter 2"},
            tracking_tool_2,
        )

        # ë³‘ë ¬ ì‹¤í–‰
        tool_calls = [
            ToolCall("tracking_tool_1", {"param1": "test1"}),
            ToolCall("tracking_tool_2", {"param2": "test2"}),
        ]

        results = await caller.execute_multiple_tools_parallel(tool_calls)

        # ê²€ì¦: ë‘ ë„êµ¬ ëª¨ë‘ í˜¸ì¶œë¨
        assert len(call_times) == 2
        assert len(results) == 2
        assert all(r.success for r in results)

        # [P3 Fix] ë™ì‹œì„± ê²€ì¦: ë‘ ë„êµ¬ê°€ ê±°ì˜ ë™ì‹œì— ì‹œì‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
        # ìˆœì°¨ ì‹¤í–‰ì´ë©´ 0.1ì´ˆ ì´ìƒ ì°¨ì´, ë³‘ë ¬ì´ë©´ 0.05ì´ˆ ì´ë‚´
        time_diff = abs(call_times[0][1] - call_times[1][1])
        assert (
            time_diff < 0.05
        ), f"Tools not started concurrently: {time_diff:.3f}s apart"

    @pytest.mark.asyncio
    async def test_parallel_execution_with_failure(self):
        """ë³‘ë ¬ ì‹¤í–‰ ì¤‘ ì¼ë¶€ ì‹¤íŒ¨ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        from app.agents.tool_caller import ToolCaller, ToolCall

        caller = ToolCaller()

        def success_tool() -> dict:
            return {"status": "ok"}

        def fail_tool() -> dict:
            raise ValueError("Intentional failure")

        caller.register_tool("success_tool", "Success", {}, success_tool)
        caller.register_tool("fail_tool", "Fail", {}, fail_tool)

        tool_calls = [
            ToolCall("success_tool", {}),
            ToolCall("fail_tool", {}),
        ]

        results = await caller.execute_multiple_tools_parallel(tool_calls)

        assert results[0].success is True
        assert results[1].success is False


# ============================================================
# Coach Fast Path Integration Tests
# ============================================================


class TestCoachFastPath:
    """Coach Fast Path í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_build_coach_query(self):
        """Coach ì¿¼ë¦¬ ë¹Œë“œ í…ŒìŠ¤íŠ¸"""
        from app.routers.coach import _build_coach_query

        # ê¸°ë³¸ ì¿¼ë¦¬
        query = _build_coach_query("KIA íƒ€ì´ê±°ì¦ˆ", [])
        assert "KIA íƒ€ì´ê±°ì¦ˆ" in query
        assert "ì¢…í•©ì ì¸ ì „ë ¥" in query

        # íŠ¹ì • focus
        query = _build_coach_query("ë‘ì‚° ë² ì–´ìŠ¤", ["bullpen", "batting"])
        assert "bullpen" in query or "ë¶ˆíœ" in query
        assert "batting" in query or "íƒ€ê²©" in query

    def test_format_coach_context(self):
        """Coach ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ… í…ŒìŠ¤íŠ¸"""
        from app.routers.coach import _format_coach_context

        tool_results = {
            "team_summary": {
                "team_name": "KIA íƒ€ì´ê±°ì¦ˆ",
                "year": 2024,
                "top_batters": [
                    {
                        "player_name": "ê¹€ë„ì˜",
                        "avg": 0.312,
                        "obp": 0.380,
                        "slg": 0.520,
                        "ops": 0.900,
                        "home_runs": 25,
                        "rbi": 80,
                    }
                ],
                "top_pitchers": [
                    {
                        "player_name": "ì–‘í˜„ì¢…",
                        "era": 3.45,
                        "whip": 1.12,
                        "wins": 12,
                        "losses": 5,
                        "saves": 0,
                        "innings_pitched": 150.0,
                    }
                ],
                "found": True,
            },
            "advanced_metrics": {
                "team_name": "KIA íƒ€ì´ê±°ì¦ˆ",
                "year": 2024,
                "metrics": {
                    "batting": {"ops": 0.750, "avg": 0.280},
                    "pitching": {"avg_era": 4.20, "qs_rate": "45%", "era_rank": "5ìœ„"},
                },
                "fatigue_index": {
                    "bullpen_share": "35%",
                    "bullpen_load_rank": "3ìœ„ (ë†’ì„ìˆ˜ë¡ ê³¼ë¶€í•˜)",
                },
                "league_averages": {"bullpen_share": "30%", "era": 4.00},
                "rankings": {"batting_ops": "4ìœ„", "batting_avg": "3ìœ„"},
            },
        }

        context = _format_coach_context(tool_results, ["batting", "bullpen"])

        assert "KIA íƒ€ì´ê±°ì¦ˆ" in context
        assert "ê¹€ë„ì˜" in context
        assert "ì–‘í˜„ì¢…" in context
        assert "ë¶ˆíœ ë¶€ë‹´ ì§€í‘œ" in context
        assert "35%" in context  # íŒ€ ë¶ˆíœ ë¹„ì¤‘
        assert "30%" in context  # ë¦¬ê·¸ í‰ê· 


# ============================================================
# Run tests
# ============================================================

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
